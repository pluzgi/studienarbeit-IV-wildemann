{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sweetviz as sv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPORT_PATH = os.path.join(\"..\", \"input\")\n",
    "TEMP_PATH = os.path.join(\"..\", \"temp\")\n",
    "OUTPUT_PATH = os.path.join(\"..\", \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden aller Dateien im .csv Format inkl. encoding und Ersetzen von \"--\" zu NaN\n",
    "def load_data(file_name):\n",
    "    file_path = os.path.join(IMPORT_PATH, file_name)\n",
    "    df = pd.read_csv(file_path, delimiter=',',  \n",
    "                     quotechar='\"',             \n",
    "                     encoding='utf-8',          \n",
    "                     na_values='--',            \n",
    "                     dtype=str)                 \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_per_day_df = load_data(\"Report_Ads-per-day.csv\")\n",
    "print(ads_per_day_df.head())\n",
    "print(ads_per_day_df.shape)\n",
    "print(ads_per_day_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_of_the_day_df = load_data(\"Report_Hour-of-the-day.csv\")\n",
    "print(hour_of_the_day_df.head())\n",
    "print(hour_of_the_day_df.shape)\n",
    "print(hour_of_the_day_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_details_df = load_data(\"Report_AdGroup_AssetDetails.csv\")\n",
    "print(asset_details_df.head())\n",
    "print(asset_details_df.shape)\n",
    "print(asset_details_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_keyword_df = load_data(\"Report_SearchKeyword.csv\")\n",
    "print(search_keyword_df.head())\n",
    "print(search_keyword_df.shape)\n",
    "print(search_keyword_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Profiling report via Sweetviz \n",
    "ads_per_day_viz = sv.analyze(ads_per_day_df)\n",
    "ads_per_day_viz.show_html(os.path.join(OUTPUT_PATH, 'ads_per_day_viz.html'))\n",
    "\n",
    "hour_of_the_day_viz = sv.analyze(hour_of_the_day_df)\n",
    "hour_of_the_day_viz.show_html(os.path.join(OUTPUT_PATH, 'hour_of_the_day_viz.html'))\n",
    "\n",
    "asset_details_viz = sv.analyze(asset_details_df)\n",
    "asset_details_viz.show_html(os.path.join(OUTPUT_PATH, 'asset_details_viz.html'))\n",
    "\n",
    "search_keyword_viz = sv.analyze(search_keyword_df)\n",
    "search_keyword_viz.show_html(os.path.join(OUTPUT_PATH, 'search_keyword_viz.html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Anpassung der NaN values im 'search_keyword_df'\n",
    "search_keyword_df['Quality Score'] = search_keyword_df['Quality Score'].fillna('0')\n",
    "search_keyword_df['Avg. engagement duration per session (seconds) (GA4)'] = search_keyword_df['Avg. engagement duration per session (seconds) (GA4)'].fillna('0')\n",
    "search_keyword_df['% Engaged sessions (GA4)'] = search_keyword_df['% Engaged sessions (GA4)'].fillna('0%')\n",
    "\n",
    "# Überprüfung der Änderungen\n",
    "print(search_keyword_df.head())\n",
    "print(search_keyword_df.isna().sum())  # Überprüfen, ob alle NaN-Werte entfernt wurden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prüfen der Anpassung\n",
    "search_keyword_viz_fin = sv.analyze(search_keyword_df)\n",
    "search_keyword_viz_fin.show_html(os.path.join(OUTPUT_PATH, 'search_keyword_viz_fin.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) Anpassung der NaN values im 'hour_of_the_day_df'\n",
    "cols_cpc = [col for col in hour_of_the_day_df.columns if 'Avg. CPC' in col]\n",
    "hour_of_the_day_df[cols_cpc] = hour_of_the_day_df[cols_cpc].apply(lambda x: x.fillna('0'))\n",
    "cols_ctr_interaction = [col for col in hour_of_the_day_df.columns if 'CTR' in col or 'Interaction rate' in col]\n",
    "hour_of_the_day_df[cols_ctr_interaction] = hour_of_the_day_df[cols_ctr_interaction].apply(lambda x: x.fillna('0%'))\n",
    "\n",
    "print(hour_of_the_day_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prüfen der Anpassung\n",
    "hour_of_the_day_viz_fin = sv.analyze(hour_of_the_day_df)\n",
    "hour_of_the_day_viz_fin.show_html(os.path.join(OUTPUT_PATH, 'hour_of_the_day_viz_fin.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schmelzen des hour_of_the_day_df DataFrames, um die Tages- und Stundenwerte zu kombinieren\n",
    "hour_of_the_day_melted = hour_of_the_day_df.melt(id_vars=['Ad group', 'Ad group ID', 'Hour of the day'], \n",
    "                                                 var_name='Day_Metric', \n",
    "                                                 value_name='Value')\n",
    "\n",
    "# Extrahieren von Tag und Metrik aus der \"Day_Metric\" Spalte\n",
    "hour_of_the_day_melted[['Day_of_week', 'Metric']] = hour_of_the_day_melted['Day_Metric'].str.extract(r'(\\w+)_(.*)')\n",
    "\n",
    "# Umbenennen der Spalten nach dem Melting und vor dem Pivoting\n",
    "hour_of_the_day_melted['Metric'] = 'Hour_' + hour_of_the_day_melted['Metric']\n",
    "\n",
    "# Pivoting des DataFrames, um die ursprüngliche Struktur zu erhalten, aber aufgeschlüsselt nach Tag und Stunde\n",
    "hour_of_the_day_pivot = hour_of_the_day_melted.pivot_table(index=['Ad group', 'Ad group ID', 'Hour of the day', 'Day_of_week'], \n",
    "                                                           columns='Metric', \n",
    "                                                           values='Value', \n",
    "                                                           aggfunc='first').reset_index()\n",
    "\n",
    "# Umbenennen der Spalten nach dem Pivoting\n",
    "hour_of_the_day_pivot.columns = ['_'.join(col).strip() if type(col) is tuple else col for col in hour_of_the_day_pivot.columns]\n",
    "hour_of_the_day_pivot.rename(columns={'Ad group': 'Ad_group', 'Ad group ID': 'Ad_group_ID', 'Hour of the day': 'Hour_of_day'}, inplace=True)\n",
    "\n",
    "# Anzeigen der ersten Zeilen des umstrukturierten DataFrames\n",
    "print(hour_of_the_day_pivot.head())\n",
    "print(hour_of_the_day_pivot.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge von ads_per_day_df und hour_of_the_day reports\n",
    "# Sicherstellen, dass die Spaltennamen in beiden DataFrames konsistent sind\n",
    "ads_per_day_df.rename(columns={'Ad group': 'Ad_group', 'Ad group ID': 'Ad_group_ID', 'Day of the week': 'Day_of_week'}, inplace=True)\n",
    "hour_of_the_day_pivot.rename(columns={'Ad group': 'Ad_group', 'Ad group ID': 'Ad_group_ID', 'Day': 'Day_of_week'}, inplace=True)\n",
    "\n",
    "# Mergen der beiden DataFrames basierend auf Ad_group_ID und Day_of_week\n",
    "merged_df = pd.merge(ads_per_day_df, hour_of_the_day_pivot, on=['Ad_group_ID', 'Day_of_week'], how='inner')\n",
    "\n",
    "# Umbenennen der Spalten mit dem Suffix `_y`\n",
    "merged_df.rename(columns={\n",
    "    'Ad_group_y': 'Hour_Ad_group',\n",
    "    'Clicks_y': 'Hour_Clicks',\n",
    "    'CTR_y': 'Hour_CTR',\n",
    "    'Cost_y': 'Hour_Cost',\n",
    "    'Impr': 'Hour_Impr',\n",
    "    'Interaction': 'Hour_Interaction'\n",
    "}, inplace=True)\n",
    "\n",
    "# Anzeigen der ersten Zeilen des gemergten DataFrames\n",
    "print(merged_df.head())\n",
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Merge: search_keyword_df und merged_df\n",
    "# Umbenennen der Spalten, um Konflikte zu vermeiden\n",
    "search_keyword_df.rename(columns={\n",
    "    'Ad group': 'Ad_group',\n",
    "    'Ad group ID': 'Ad_group_ID',\n",
    "    'Impr.': 'Keyword_Impr',\n",
    "    'Clicks': 'Keyword_Clicks',\n",
    "    'CTR': 'Keyword_CTR',\n",
    "    'Cost': 'Keyword_Cost',\n",
    "    'Avg. CPC': 'Keyword_Avg_CPC',\n",
    "    '% Engaged sessions (GA4)': 'Keyword_%-Engaged_sessions',\n",
    "    'Avg. engagement duration per session (seconds) (GA4)': 'Keyword_Engagement_seconds'\n",
    "}, inplace=True)\n",
    "\n",
    "# Auswahl der relevanten Spalten aus search_keyword_df\n",
    "search_keyword_df = search_keyword_df[['Ad_group_ID', 'Search keyword', 'Keyword_Impr', 'Keyword_Clicks', 'Keyword_CTR', 'Keyword_Cost', 'Keyword_Avg_CPC', 'Keyword_%-Engaged_sessions', 'Keyword_Engagement_seconds']]\n",
    "\n",
    "# Mergen der DataFrames basierend auf Ad_group_ID\n",
    "merged_df = pd.merge(merged_df, search_keyword_df, on='Ad_group_ID', how='inner')\n",
    "\n",
    "# Anzeigen der ersten Zeilen des gemergten DataFrames\n",
    "print(merged_df.head())\n",
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Merge: asset_details_df und merged_df\n",
    "# Umbenennen der Spalten, um Konflikte zu vermeiden\n",
    "asset_details_df.rename(columns={\n",
    "    'Ad group': 'Ad_group',\n",
    "    'Ad group ID': 'Ad_group_ID',\n",
    "    'Impr.': 'Asset_Impr'\n",
    "}, inplace=True)\n",
    "\n",
    "# Auswahl der relevanten Spalten aus asset_details_df\n",
    "asset_details_df = asset_details_df[['Ad_group_ID', 'Asset', 'Asset type', 'Asset_Impr']]\n",
    "\n",
    "# Mergen der DataFrames basierend auf Ad_group_ID\n",
    "merged_df = pd.merge(merged_df, asset_details_df, on='Ad_group_ID', how='inner')\n",
    "\n",
    "# Anzeigen der ersten Zeilen des final gemergten DataFrames\n",
    "print(merged_df.head(10))\n",
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entfernen der Spalten \"Ad_group_y\" und \"Mobile final URL\"\n",
    "merged_df.drop(columns=['Hour_Ad_group'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.head(10))\n",
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation der fehlenden Werte mit \"0\" und \"0%\"\n",
    "columns_to_impute_numeric = ['Avg. engagement duration per session (seconds) (GA4)', 'Events / session (GA4)']\n",
    "column_to_impute_percent = '% Engaged sessions (GA4)'\n",
    "\n",
    "# Auffüllen der numerischen Spalten mit \"0\"\n",
    "for column in columns_to_impute_numeric:\n",
    "    merged_df[column] = merged_df[column].fillna(0)\n",
    "\n",
    "# Auffüllen der prozentualen Spalte mit \"0%\"\n",
    "merged_df[column_to_impute_percent] = merged_df[column_to_impute_percent].fillna(\"0%\")\n",
    "\n",
    "# Entfernen des Prozentzeichens aus den relevanten Spalten, ohne die Werte zu konvertieren\n",
    "percent_columns = [\n",
    "    'Hour_CTR', 'Hour_Interaction rate', 'CTR', \n",
    "    'Keyword_CTR', 'Keyword_%-Engaged_sessions'\n",
    "]\n",
    "\n",
    "# Funktion zum Entfernen des Prozentzeichens\n",
    "def remove_percent(column):\n",
    "    return column.str.rstrip('%')\n",
    "\n",
    "# Anwenden der Funktion auf die ausgewählten Spalten\n",
    "for col in percent_columns:\n",
    "    merged_df[col] = remove_percent(merged_df[col])\n",
    "\n",
    "# Überprüfen der Änderungen\n",
    "print(merged_df[percent_columns].head())\n",
    "\n",
    "# Überprüfen, ob alle fehlenden Werte aufgefüllt wurden\n",
    "print(merged_df[columns_to_impute_numeric + [column_to_impute_percent]].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Um in den Transformer pipelines auf Textspezifika zugreifen zu können, werden hier vor dem Train-test-split einen Word count erzeugen.\n",
    "def count_words(text):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    return len(str(text).split())\n",
    "\n",
    "# List of text columns to process\n",
    "text_features = ['Asset', \"Search keyword\"]\n",
    "\n",
    "# Apply the word count function to each text column and store the result in a new column\n",
    "for feature in text_features:\n",
    "    merged_df[f'{feature}_word_count'] = merged_df[feature].apply(count_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test-split & export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aufteilung Traings- und Testdaten\n",
    "train_df, test_df = train_test_split(merged_df, train_size=.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Speichern im .pickle Format\n",
    "train_df.to_pickle(os.path.join(TEMP_PATH, \"train.pickle\"))\n",
    "test_df.to_pickle(os.path.join(TEMP_PATH, \"test.pickle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(os.path.join(TEMP_PATH, \"train.pickle\"))\n",
    "train_df.head()\n",
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ges_train = sv.analyze(train_df, pairwise_analysis='off')\n",
    "ges_train.show_html('ges_train.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auswahl der Variablen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auswahl der numerischen und kategorialen Variablen\n",
    "numerical_features = [\n",
    "    'Clicks', 'Cost', 'Avg. CPC', \n",
    "    'Hour_Clicks', 'Hour_Cost', 'Hour_Impr.', 'Hour_Interaction rate',\n",
    "    'Keyword_Impr', 'Keyword_Clicks', 'Keyword_Cost', 'Keyword_Avg_CPC',\n",
    "    'Keyword_Engagement_seconds', 'Asset_Impr', 'Asset_word_count', 'Search keyword_word_count'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'Search keyword', 'Asset', 'Asset type', 'Day_of_week'\n",
    "]\n",
    "\n",
    "# Zielvariable (Target)\n",
    "target = 'CTR'\n",
    "\n",
    "# Erstellen eines  DataFrames mit den ausgewählten Variablen\n",
    "train_df = train_df[numerical_features + categorical_features + [target]]\n",
    "\n",
    "# Überprüfen der ersten Zeilen des neuen DataFrames\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung statistischer Analysen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setzen des Stils für die Plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Korrelationen zwischen den numerischen Variablen berechnen\n",
    "corr = train_df[numerical_features].corr()\n",
    "\n",
    "# Heatmap der Korrelationen erstellen\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Korrelation zwischen numerischen Variablen')\n",
    "plt.show()\n",
    "\n",
    "# Verteilung der numerischen Variablen plotten\n",
    "train_df[numerical_features].astype(float).hist(bins=30, figsize=(20, 15))\n",
    "plt.suptitle('Verteilung der numerischen Variablen')\n",
    "plt.show()\n",
    "\n",
    "# Paarplot der numerischen Variablen\n",
    "sns.pairplot(train_df[numerical_features].astype(float))\n",
    "plt.suptitle('Paarplot der numerischen Variablen')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot der Zielvariablen im Verhältnis zu den numerischen Variablen\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, col in enumerate(numerical_features, 1):\n",
    "    plt.subplot(4, 4, i)\n",
    "    sns.boxplot(x=train_df[target], y=train_df[col].astype(float))\n",
    "    plt.title(f'Boxplot von {col} im Verhältnis zu {target}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Zählplot für kategoriale Variablen\n",
    "plt.figure(figsize=(20, 20))\n",
    "num_plots = len(categorical_features)\n",
    "cols = 4\n",
    "rows = (num_plots // cols) + (num_plots % cols > 0)\n",
    "\n",
    "for i, col in enumerate(categorical_features, 1):\n",
    "    plt.subplot(rows, cols, i)\n",
    "    sns.countplot(y=train_df[col])\n",
    "    plt.title(f'Zählplot von {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
